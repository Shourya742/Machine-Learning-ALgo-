{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "### Goal of lesson\n",
        "- Understand what Convolutional Neural Network (CNN) is\n",
        "- The strength of CNN\n",
        "- How to use it to detect handwriting\n",
        "- Extract features from pictures\n",
        "- Learn Convolution, Pooling and Flatten\n",
        "- How to create a CNN\n",
        "\n",
        "### Computer Vision\n",
        "- Computational methods for analyzing and understanding digital images"
      ],
      "metadata": {
        "id": "cbm_UBBirv8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handwriting detection\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/img/handwritten_numbers.png\" width=\"600\" align=\"left\">"
      ],
      "metadata": {
        "id": "auAni6tarzeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive approach\n",
        "#### Map one pixel to input network - have some hidden layers - then detect.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/img/pixel_numbers.png\" width=\"600\" align=\"left\">"
      ],
      "metadata": {
        "id": "WalmT_uMr2kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss of information in the structure of the image\n",
        "<img src=\"https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/img/dnn_example.png\" width=\"600\" align=\"left\">"
      ],
      "metadata": {
        "id": "qNuA3mpxr5Ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Convolution\n",
        "- applying a filter that adds each pixel value of an image to its neighbors, weighted according to a kernel matix"
      ],
      "metadata": {
        "id": "MP1eD5MSr7-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example of edge detection\n",
        "- Using this filter"
      ],
      "metadata": {
        "id": "GbM3LHV9r_Tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Programming Notes:\n",
        "> - Libraries used\n",
        ">     - [**PIL**](https://pillow.readthedocs.io/en/stable/) Python Imaging Library"
      ],
      "metadata": {
        "id": "rqETVR5DsCfU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c3tB8YFjra_Z"
      },
      "outputs": [],
      "source": [
        "from PIL import Image,ImageFilter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image=Image.open('https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/img/dobermann.jpg').convert('RGB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "0V4YVNSc2xEq",
        "outputId": "e38ae23b-19f4-43ab-a9be-9ef62254cacd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c92afc8ac13b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/img/dobermann.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/img/dobermann.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filterd = image.filter(ImageFilter.kernel(size(3,3),kernel=[-1,-1,-1,-1,8,-1,-1,-1,-1,-1],scale=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "4LKtDi2b3PGO",
        "outputId": "7a06e5e5-04b2-4d00-cc38-9395c2a9b687"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-85cfd869fb25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilterd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageFilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(filterd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "w32dn60c3eAZ",
        "outputId": "5086b608-e6bc-4c84-b623-fc09b2ad402b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6250954ba791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilterd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'filterd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(image)"
      ],
      "metadata": {
        "id": "ct4QQvS33iqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pooling\n",
        "- Reducing the size of an input by sampling from regoins in the input\n",
        "- Bascially reducing the size of the image\n",
        "\n",
        "### Max-Pooling\n",
        "- Pooling by choosing the maximum value in each region"
      ],
      "metadata": {
        "id": "FMxfutjSsH9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Network (CNN)\n",
        "- Neural Networks that use convolution for analyzing images"
      ],
      "metadata": {
        "id": "b_O2Py8EsL2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Idea of CNN\n",
        "- Input image\n",
        "- Apply Convolution - possible several to get several features of the image (feature maps)\n",
        "- Apply pooling (this reduces the input)\n",
        "- Then flatten it out to traditional network\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/img/cnn_example.png' width=600, align='left'>"
      ],
      "metadata": {
        "id": "w7F2ji6XsOjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Programming Notes:\n",
        "> - Libraries used\n",
        ">     - [**tensorflow**](https://www.tensorflow.org) - end-to-end open source machine learning platform\n",
        "> - Functionality and concepts used\n",
        ">     - [**to_categorical**](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) Converts a class vector (integers) to binary class matrix.\n",
        ">     - [**Sequential**](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) provides training and inference features for a model\n",
        ">     - [**Dense**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) regular densely-connected Neural Network (NN) layer.\n",
        ">     - [**Dropout**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) applies Dropout to the input\n",
        ">     - [**Conv2D**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) 2D convolution layer\n",
        ">     - [**MaxPooling2D**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) max pooling operation for 2D spatial data\n",
        ">     - [**Flatten**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) flattens the input"
      ],
      "metadata": {
        "id": "oSvcPqGvsRZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "hdTD7cs_sUKr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "Zqcn1KUt72U7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI59ESRo78Mp",
        "outputId": "8db2cc9d-12d8-4adc-9fb4-b9d069fa45a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape, x_test.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwsYGyZx8_iu",
        "outputId": "f8dd0b98-4d7e-494c-aee4-29c7058e59a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index=2\n",
        "img =Image.fromarray(x_train[index])\n",
        "print(y_train[index])\n",
        "display(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "jPnvWAq89cby",
        "outputId": "bc2ce91b-3dfb-4d8f-a9eb-d7c76f6cc4e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F1B80388D60>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMTAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjwFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEVj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train/255.0\n",
        "x_test=x_test/255.0"
      ],
      "metadata": {
        "id": "dgo9_V1696r7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)"
      ],
      "metadata": {
        "id": "hcByADYg-BOt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZHLDZJF-M8H",
        "outputId": "da6fe683-bc27-4f97-8fd5-6483d77a8c62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBMOizo--WS1",
        "outputId": "0e83ba5a-7f04-4982-d57e-9b0ed036d7bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
        "x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)"
      ],
      "metadata": {
        "id": "jYBgxltm-auc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAV-2ZBj-sxa",
        "outputId": "8729e41a-ec5a-4f4b-9b95-e90514c5ef67"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "puE2SIpF-wdV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,epochs=10)\n",
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z0OaL5NAJdF",
        "outputId": "0f394062-2f74-47f7-8a83-b90dd76909bf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2539 - accuracy: 0.9260\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1024 - accuracy: 0.9687\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0771 - accuracy: 0.9765\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0643 - accuracy: 0.9804\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0536 - accuracy: 0.9832\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0461 - accuracy: 0.9847\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0419 - accuracy: 0.9862\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0373 - accuracy: 0.9877\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0305 - accuracy: 0.9901\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0296 - accuracy: 0.9903\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0422 - accuracy: 0.9877\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.042228538542985916, 0.9876999855041504]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}